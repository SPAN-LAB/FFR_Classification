{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dadfb1d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T12:17:27.860844Z",
     "start_time": "2025-10-24T12:17:27.857558Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from pathlib import Path\n",
    "from pymatreader import read_mat\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedShuffleSplit\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa787f57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T12:19:05.951735Z",
     "start_time": "2025-10-24T12:19:05.255768Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anushukla/Desktop/SPAN/FFR_Classification_app/.venv/lib/python3.12/site-packages/pymatreader/utils.py:179: UserWarning: Complex objects (like classes) are not supported. They are imported on a best effort base but your mileage will vary.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3458, 4997])\n"
     ]
    }
   ],
   "source": [
    "from EEGDataStructures import EEGSubject\n",
    "SUBJECT_FILE = '../data/4T1004.mat'\n",
    "subject = EEGSubject.init_from_filepath(SUBJECT_FILE)\n",
    "subject.use_raw_labels()\n",
    "X, y, t, idx = subject.to_arrays(as_torch = True)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a054c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "[001] train loss=1.3626 acc=0.277 | val loss=1.8199 acc=0.213\n",
      "[002] train loss=1.3211 acc=0.357 | val loss=1.5377 acc=0.247\n",
      "[003] train loss=1.3036 acc=0.413 | val loss=1.3537 acc=0.348\n",
      "[004] train loss=1.2978 acc=0.402 | val loss=1.2884 acc=0.483\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43msubject\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCNN\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../outputs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SPAN/FFR_Classification_app/src/EEGDataStructures.py:520\u001b[39m, in \u001b[36mEEGSubject.train\u001b[39m\u001b[34m(self, model_name, num_epochs, lr, output_dir, stopping_criteria)\u001b[39m\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fold_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_folds):\n\u001b[32m    517\u001b[39m     train_dl, val_dl, _ = \u001b[38;5;28mself\u001b[39m.create_dataloaders(\n\u001b[32m    518\u001b[39m         fold_idx=fold_idx, add_channel_dim = add_channel_dim\n\u001b[32m    519\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     res = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimestamps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_idx+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mbest_val_acc\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SPAN/FFR_Classification_app/src/train_model.py:81\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model_name, model_kwargs, train_loader, val_loader, num_epochs, lr, output_dir, device, stopping_criteria)\u001b[39m\n\u001b[32m     78\u001b[39m optimizer.step()\n\u001b[32m     80\u001b[39m preds = logits.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m total_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m * y.numel()\n\u001b[32m     82\u001b[39m total_correct += (preds == y).sum().item()\n\u001b[32m     83\u001b[39m total_n += y.numel()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "subject.subaverage(size = 3)\n",
    "subject.train(model_name = \"CNN\", output_dir = \"../outputs\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac1ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_model import run_model\n",
    "import json\n",
    "with open(\"../outputs/folds_meta.json\") as f:\n",
    "    fold_meta = json.load(f)\n",
    "\n",
    "    for meta in fold_meta:\n",
    "        fold_num = meta[\"fold_num\"]\n",
    "        test_idx = np.array(meta[\"test_idx\"], dtype=np.int64)\n",
    "        ckpt     = meta[\"best_ckpt\"]\n",
    "        _, _, test_dl = subject.create_dataloaders(fold = fold,\n",
    "                                                   fold_num = fold_num)\n",
    "        \n",
    "        test_res = run_model(\n",
    "        model_name=\"CNN\",\n",
    "        model_kwargs={},\n",
    "        dataloader=test_dl,\n",
    "        weights_path=ckpt,\n",
    "        output_dir=str(Path(f\"../outputs/fold_{fold_num}\")),\n",
    "        )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
