{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3cdf77c-881f-464f-8ee0-a5b834d021f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in file: ['#refs#', 'ffr_dss', 'ffr_nodss', 'labels', 'time']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, roc_curve, auc\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import os\n",
    "\n",
    "#file_path = r\".\\4tone_cell\\4T1006.mat\"\n",
    "file_path = r\"Z:\\projects\\trial_classification\\4tone_cell\\4T1005.mat\"\n",
    "\n",
    "file = h5py.File(file_path, 'r')\n",
    "filename = os.path.basename(file.filename)\n",
    "print(\"Keys in file:\", list(file.keys()))\n",
    "\n",
    "ffr_nodss = file[\"ffr_nodss\"][:]  \n",
    "labels_ref = file[\"labels\"][:]\n",
    "t = file[\"time\"][:].flatten()\n",
    "\n",
    "labels = np.array([\n",
    "    int(file[ref][()].tobytes().decode('ascii').strip('\\x00'))\n",
    "    for ref in labels_ref[0]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d135a338-3401-4f9f-855f-ef397b0b72ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed shape: (3093, 3277), Time range: 49.98779296875 – 249.93896484375\n",
      "After averaging: (61, 3277) (61,)\n"
     ]
    }
   ],
   "source": [
    "xmin, xmax = 50, 250\n",
    "\n",
    "xmin_ind = np.argmin(np.abs(t - xmin))   \n",
    "xmax_ind = np.argmin(np.abs(t - xmax))   \n",
    "\n",
    "\n",
    "ffr_trimmed = ffr_nodss[:, xmin_ind:xmax_ind]\n",
    "t_trimmed = t[xmin_ind:xmax_ind]\n",
    "\n",
    "print(f\"Trimmed shape: {ffr_trimmed.shape}, Time range: {t_trimmed[0]} – {t_trimmed[-1]}\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(ffr_trimmed)\n",
    "df['label'] = labels\n",
    "df.columns = [f't{t_i}' for t_i in range(ffr_trimmed.shape[1])] + ['label']\n",
    "\n",
    "group_size = 50\n",
    "num_groups = len(df) // group_size\n",
    "\n",
    "X_avg = np.array([\n",
    "    df.iloc[i*group_size:(i+1)*group_size, :-1].mean(axis=0).values\n",
    "    for i in range(num_groups)\n",
    "])\n",
    "y_avg = np.array([\n",
    "    df.iloc[i*group_size:(i+1)*group_size]['label'].mode()[0]\n",
    "    for i in range(num_groups)\n",
    "])\n",
    "\n",
    "print(\"After averaging:\", X_avg.shape, y_avg.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a49a794f-3d60-4fcc-85c5-2388237371b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation accuracies: [0.84615385 0.66666667 0.83333333 0.83333333 0.91666667]\n",
      "Mean CV Accuracy: 0.819\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       1.00      1.00      1.00        11\n",
      "           4       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        61\n",
      "   macro avg       1.00      1.00      1.00        61\n",
      "weighted avg       1.00      1.00      1.00        61\n",
      "\n",
      "Macro F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "lda_pipeline = make_pipeline(StandardScaler(), LinearDiscriminantAnalysis())\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(lda_pipeline, X_avg, y_avg, cv=kf)\n",
    "print(f\"\\nCross-validation accuracies: {scores}\")\n",
    "print(f\"Mean CV Accuracy: {np.mean(scores):.3f}\")\n",
    "\n",
    "lda_pipeline.fit(X_avg, y_avg)\n",
    "y_pred = lda_pipeline.predict(X_avg)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_avg, y_pred))\n",
    "print(\"Macro F1-score:\", f1_score(y_avg, y_pred, average='macro'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c8d83-9e61-4a88-b18f-65ad5c4691b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_avg, y_pred)\n",
    "print(\"\\nConfusion Matrix (50Trial):\\n\", cm)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix 50 trial\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, str(cm[i,j]), ha='center', va='center', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0688c0-52f7-4eb6-aea2-48ff7a046cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_avg)\n",
    "y_bin = label_binarize(y_avg, classes=classes)\n",
    "y_score = lda_pipeline.predict_proba(X_avg)  \n",
    "plt.figure(figsize=(6,5))\n",
    "for i, cls in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve(y_bin[:, i], y_score[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f'Class {cls} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0,1],[0,1],'k--', lw=1)  # diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve (50 trials avg)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ede48c8-12c0-4a00-8c8b-a7b7f1ca3f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
